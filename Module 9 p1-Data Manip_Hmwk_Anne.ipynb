{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5082fa",
   "metadata": {},
   "source": [
    "# Module 9: Data Manipulation I \n",
    "\n",
    "Datasets rarely come perfectly ready for analysis. Sometimes they need a little cleaning up, modification, or adjustment to meet the needs of your analyses. In our first lesson on data manipulation, you will learn some of the basic tools in making minor adjustments to your dataset. \n",
    "\n",
    "***************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f30cd",
   "metadata": {},
   "source": [
    "## Creating Data From Scratch\n",
    "\n",
    "Datasets are an organized series of lists of information. We can use what we've learned about dictionaries to quickly create a series of labels and values that can be turned into a dataset. This will allow you to see the information in a structured and organized way, but it also allows for the application of pandas functions on this new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99604f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Create a dictionary with you key-value pairs\n",
    "\n",
    "## KEY = the column header; this is the name of your column in the new dataset\n",
    "## VALUE = the values that will be included in the column; this will be a list\n",
    "\n",
    "dictionary1 = {'First Score':[100, 90, 89, 95], ##key is \"First Score\"\n",
    "            'Second Score': [30, 45, 56, 67], ## value is the list of scores\n",
    "            'Third Score':[78, 40, 80, 98]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa567b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Convert the dictionary to a pandas dataframe\n",
    "\n",
    "df = pd.DataFrame(dictionary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Check your new dataset\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c20238",
   "metadata": {},
   "source": [
    "## { Exercise 1 }\n",
    "\n",
    "Create a dataset (name it whatever you like) with the following columns:\n",
    "* TV Shows\n",
    "* Movies\n",
    "* Snacks\n",
    "\n",
    "Make sure each column has at least four observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20918b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0141b19-db12-46ef-950a-3d11d58f540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43a37ba-7bbe-4210-aad2-1c40c65002e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leisure= {\"tv shows\":[\"Dateline\", \"60 minutes\", \"questions for a winner\", \"news easy\"], \"Movies\": [\"A good liar\", \"Evita\", \"My friend the lion\", \"once upon a time\"], \"Snacks\":[\"Cheese\", \"Crakers\", \"Bread\", \"Cranberies\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b2fae7-be49-4cb1-842a-a2c4f9b32888",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=pd.DataFrame(leisure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59f53b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv shows</th>\n",
       "      <th>Movies</th>\n",
       "      <th>Snacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dateline</td>\n",
       "      <td>A good liar</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60 minutes</td>\n",
       "      <td>Evita</td>\n",
       "      <td>Crakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>questions for a winner</td>\n",
       "      <td>My friend the lion</td>\n",
       "      <td>Bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news easy</td>\n",
       "      <td>once upon a time</td>\n",
       "      <td>Cranberies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tv shows              Movies      Snacks\n",
       "0                Dateline         A good liar      Cheese\n",
       "1              60 minutes               Evita     Crakers\n",
       "2  questions for a winner  My friend the lion       Bread\n",
       "3               news easy    once upon a time  Cranberies"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b61878",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c1478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3734f0b",
   "metadata": {},
   "source": [
    "## Finding & Handling Missing Data\n",
    "\n",
    "Missing data is something that always needs to be accessed when you are working with a new dataset. Missing data is missing information and creates gaps in your dataset. For certain functions and analyses, you cannot have any missing data. Luckily, you are able to handle the missing data in several ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a dataset to practice with\n",
    "\n",
    "dict1 = {'Name':[\"James\", \"Patrick\", np.nan, \"Cassie\", \"Mario\"],\n",
    "        'Sport': [\"Baseball\", \"Tennis\", \"Soccer\", np.nan, \"Basketball\"],\n",
    "        'Score':[np.nan, 40, 80, np.nan, 78]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9203adc",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Locating Missing Data\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd00fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking which rows have missing data and how much data is missing\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## where are the rows that have missing data?\n",
    "\n",
    "df.loc[df.isnull().any(axis = 1)]\n",
    "\n",
    "## any() function: the any looks for any true value across an axis\n",
    "## axis = 1 means the columns - the function will look at each row across each column\n",
    "## if any of the columns have ONE missing value, the row will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b65b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## where are the rows that have missing data in a specific column?\n",
    "\n",
    "df.loc[df[\"Sport\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b361b7",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Removing Missing Data\n",
    "\n",
    "***\n",
    "\n",
    "#### What does it mean to make a change \"inplace\"?\n",
    "\n",
    "When inplace = True, the data is modified in place (the dataset is permanently updated). When inplace = False (this is the default operation), the operation is performed and a <b>copy</b> of the modified dataset is returned, but the original dataset remains unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a dataset to practice with\n",
    "\n",
    "dict1 = {'Name':[\"James\", \"Patrick\", np.nan, \"Cassie\", \"Mario\"],\n",
    "        'Sport': [\"Baseball\", \"Tennis\", \"Soccer\", np.nan, \"Basketball\"],\n",
    "        'Score':[np.nan, 40, 80, np.nan, 78]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3529c2",
   "metadata": {},
   "source": [
    "#### Removing All Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e3d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## dropping all rows with at least one missing value\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "## check the changes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602ef6d",
   "metadata": {},
   "source": [
    "#### Removing Specific Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a07a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Name':[\"James\", \"Patrick\", np.nan, \"Cassie\", \"Mario\"],\n",
    "        'Sport': [\"Baseball\", \"Tennis\", \"Soccer\", np.nan, \"Basketball\"],\n",
    "        'Score':[np.nan, 40, 80, np.nan, 78]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "\n",
    "### dropping all rows with at least one missing value in a certain column\n",
    "\n",
    "df.dropna(subset=[\"Name\"], inplace = True)\n",
    "\n",
    "## check the changes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe758c3",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Replacing Missing Data\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd48415",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Name':[\"James\", \"Patrick\", np.nan, \"Cassie\", \"Mario\"],\n",
    "        'Sport': [\"Baseball\", \"Tennis\", \"Soccer\", np.nan, \"Basketball\"],\n",
    "        'Score':[np.nan, 40, 80, np.nan, 78]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "\n",
    "#### fill all missing data values with a value of your choosing\n",
    "\n",
    "df.fillna(999, inplace = True)\n",
    "\n",
    "# check changes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc386b27",
   "metadata": {},
   "source": [
    "#### Replacing Specific Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c183bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Name':[\"James\", \"Patrick\", np.nan, \"Cassie\", \"Mario\"],\n",
    "        'Sport': [\"Baseball\", \"Tennis\", \"Soccer\", np.nan, \"Basketball\"],\n",
    "        'Score':[np.nan, 40, 80, np.nan, 78]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "\n",
    "#### fill specific missing data values with a value of your choosing\n",
    "\n",
    "df[\"Name\"].fillna(\"Unknown\", inplace = True)\n",
    "\n",
    "# check changes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b489ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict1 = {'Name':[\"James\", \"Patrick\", np.nan, \"Cassie\", \"Mario\"],\n",
    "        'Sport': [\"Baseball\", \"Tennis\", \"Soccer\", np.nan, \"Basketball\"],\n",
    "        'Score':[np.nan, 40, 80, np.nan, 78]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "\n",
    "## fill specific missing values with summary statistic\n",
    "## replace the missing score value with the average score for the entire group\n",
    "\n",
    "# what is the average?\n",
    "print(\"The average score is:\", df[\"Score\"].mean())\n",
    "\n",
    "# use that value to fill in the missing value\n",
    "df[\"Score\"].fillna(df[\"Score\"].mean(), inplace = True)\n",
    "\n",
    "# check changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d4641",
   "metadata": {},
   "source": [
    "## { Exercise 2 }\n",
    "\n",
    "Run the code to create a dataset of weather conditions in specific areas. Then find and handle all the missing data in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weather Dataset\n",
    "\n",
    "weather = {'Season':[\"Spring\", \"Spring\", np.nan, \"Summer\", \"Fall\", \"Winter\", \"Summer\", \"Summer\", \"Winter\"],\n",
    "            'Temp': [90, 71, np.nan, 102, 68, np.nan, 99, 87, np.nan],\n",
    "            'Conditions':[\"Rain\", \"Thunderstorms\", \"Rain\", \"Sunny\", \"Partly Cloudy\", np.nan, \"Cloudy\", np.nan, \"Blizzard\"]}\n",
    "\n",
    "df = pd.DataFrame(weather)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb1972",
   "metadata": {},
   "source": [
    "1. Write the code to show how much missing data is in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42acc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0a5b6c3",
   "metadata": {},
   "source": [
    "2. Using loc - return the rows that have any missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3065e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf366e52",
   "metadata": {},
   "source": [
    "3. Drop the rows that have missing data in \"Season\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b9645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41416533",
   "metadata": {},
   "source": [
    "4. Replace the missing data in the \"Conditions\" column with the word \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b42f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21f4955",
   "metadata": {},
   "source": [
    "5. Replace the missing data in the \"Temp\" column with the average temperature of the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0daa434",
   "metadata": {},
   "source": [
    "## Finding & Handling Duplicate Rows\n",
    "\n",
    "Duplicate data is typically an error in data entry - the same information is getting entered more than once. Duplicate rows can be just as messy for analyses as missing data. You should take the time to determine if you have any duplicate rows in your dataset - and if you do, they should be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f203945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a dataset to practice with\n",
    "\n",
    "paint = {'Paint_Brand':[\"Benjamin Moore\", \"Behr\", \"Sherwin-Williams\", \"Kilz\", \"Valspar\", \"Sherwin-Williams\", \"Kilz\"],\n",
    "        'Color': [\"Beige\", \"Navy\", \"Cream\", \"Grey\", \"Soft Teal\", \"Cream\", \"Grey\"],\n",
    "        'Wall_Location':[\"Entryway\", \"Master Bedroom\", \"Kitchen\", \"Basement\", \"Living Room\", \"Kitchen\", \"Basement\"]}\n",
    "\n",
    "df = pd.DataFrame(paint)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846aba4",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Identifying Duplicate Rows\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d18fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## locate duplicate rows \n",
    "\n",
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d42db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop duplicate rows\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "# check work\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f999706",
   "metadata": {},
   "source": [
    "## Adding & Removing Columns from Dataset\n",
    "\n",
    "You have a lot of flexibility with what you can do with your pandas dataset once its defined. Adding columns allows you to create new data that may not have originated in your starting data file. It also allows you to create columns based on other columns or conditions. Removing columns allows you to remove unneeded information from your dataset which might be taking up space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a3bb",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Creating New Columns\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b844c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create a new column and assign a single value\n",
    "\n",
    "df[\"Quantity\"] = 3\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a new column \n",
    "\n",
    "df[\"Price\"] = 29.99\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab43993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create a new column and assign everything to missing\n",
    "\n",
    "df[\"Total\"] = np.nan\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33042545",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Creating New Column based on other Columns\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a new column based on another column\n",
    "\n",
    "df[\"Total_Cost\"] = df[\"Quantity\"] * df[\"Price\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f3612",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Removing Columns\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop a single column\n",
    "\n",
    "df.drop(columns = \"Total\", inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop multiple columns\n",
    "\n",
    "df.drop(columns = [\"Quantity\", \"Price\"], inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295e4ce",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Creating New Columns based on Conditions\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a dataset to practice with\n",
    "\n",
    "grades = {'Student':[\"Taylor\", \"Carlos\", \"Sherrie\", \"Mary\", \"Henry\", \"Michael\", \"June\"],\n",
    "        'Grades': [89, 99, 100, 79, 81, 78, 97],\n",
    "        'Subject':[\"Math\", \"English\", \"Studio Art\", \"Biology\", \"Chemistry\", \"Latin\", \"Physics\"]}\n",
    "\n",
    "df = pd.DataFrame(grades)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df740a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a new column based on the condition of another column\n",
    "\n",
    "## the np.where function returns elements based on a condition\n",
    "## np.where(condition, outcome a, outcome b)\n",
    "## condition = whatever condition you want to search for \n",
    "## outcome a = what to do when the condition is true\n",
    "## outcome b = what to do when the condition is false\n",
    "\n",
    "df[\"Pass_Fail\"] = np.where(df[\"Grades\"] >= 80, \"Passed\", \"Failed\")\n",
    "\n",
    "# check your work\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7be2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create a new column based on multiple conditions\n",
    "\n",
    "## the np.where function returns elements based on a condition\n",
    "## np.where(condition, outcome a, outcome b)\n",
    "## condition = whatever condition you want to search for \n",
    "## outcome a = what to do when the condition is true\n",
    "## outcome b = what to do when the condition is false\n",
    "\n",
    "df[\"Honor_Role\"] = np.where(((df[\"Pass_Fail\"] == \"Passed\") & (df[\"Grades\"] > 89)), 1, 0)\n",
    "\n",
    "# check your work\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d771669",
   "metadata": {},
   "source": [
    "## { Exercise 3 }\n",
    "\n",
    "Run the code below to create a dataset about vacation packages. After you create the dataset, answer the questions below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vacation Data\n",
    "\n",
    "vaca = {'Country_Destination':[\"Barbados\", \"Mexico\", \"Australia\", \"Aruba\", \"Greece\", \"France\", \"France\"],\n",
    "            'Inclusive': [\"Y\", \"N\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\"],\n",
    "            'Price_per_Person':[1098.00, 679.99, 2035.69, 1789.00, 899.00, 1650.89, 1650.89], \n",
    "            'Family_Size':[2, 4, 1, 6, 5, 3, 3],\n",
    "            'Travel_Month':[\"June\", \"September\", \"April\", \"November\", \"August\", \"December\", \"December\"]}\n",
    "\n",
    "df = pd.DataFrame(vaca)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b0477",
   "metadata": {},
   "source": [
    "1. Identify and remove the duplicate row(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d10029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76bf58ec",
   "metadata": {},
   "source": [
    "2. Add a column to the dataset called \"Travel_Insurance\" -- all the values in the column should be \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd805a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5403496b",
   "metadata": {},
   "source": [
    "3. Add a column to the dataset called \"Price_per_Family\" -- multiply the \"Price_per_Person\" column with the \"Family_Size\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99887b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4169a1e",
   "metadata": {},
   "source": [
    "4. Add a new column called \"Peak Season\" -- if the Travel month is a summer month, \"Peak Season\" should have a value of \"Y\", otherwise, it should have a value of \"N\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67df29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "379b656d",
   "metadata": {},
   "source": [
    "5. Add a new column called \"Luxury Tax\" -- if \"Peak Season\" is \"Y\", \"Luxury Tax\" should have a value of 300.00, otherwise, it should have a value of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbecc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0f7a788",
   "metadata": {},
   "source": [
    "6. Add a new column called \"Total Price\" -- add the columns \"Price_per_Family\" and \"Luxury Tax\" to get the total price of the trip per family. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9daa58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e14acd86",
   "metadata": {},
   "source": [
    "# { Module 9 Homework }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6df37",
   "metadata": {},
   "source": [
    "1. Import the two libraries needed to work with your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mumpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf7949",
   "metadata": {},
   "source": [
    "2. Import the \"Dental Patients 2.xlsx\" dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=pd.read_excel(\"Dental Patients 2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc57dae-d6dd-4663-bc39-29a0ff08a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63cddd",
   "metadata": {},
   "source": [
    "3. Explore the characteristics of your dataset. Find the following:\n",
    "    * the first 5 rows\n",
    "    * the last 5 rows\n",
    "    * the shape of the dataset (number of rows and columns)\n",
    "    * the descriptive statistics for the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7b85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f875218e",
   "metadata": {},
   "source": [
    "4. What are the summary characteristics of the dataset? Use the info function to print the details. Jot down two observations you have about this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e1f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45e25db",
   "metadata": {},
   "source": [
    "5. Locate the columns that have missing data. Which column has the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e99747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d39987ec",
   "metadata": {},
   "source": [
    "6. Using the column that is missing the most data, locate and return the rows where the data is missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b6279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0185d11",
   "metadata": {},
   "source": [
    "7. Using the column that is missing the most data, replace the missing values with \"Unknown - Ask Patient\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130c174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d31972c",
   "metadata": {},
   "source": [
    "8. Replace the missing values in the \"EmergencyContact\" column with \"Unknown - Ask Patient\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ce40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37f862f",
   "metadata": {},
   "source": [
    "9. Replace the missing values in the \"Age\" column with the average age of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbb68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02cc8c6b",
   "metadata": {},
   "source": [
    "10. Now that you've filled the missing values for a few rows, drop the remaining rows that have any missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c4b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08d6b6ec",
   "metadata": {},
   "source": [
    "11. Check the dataset for duplicate rows. If you have any, remove them from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f4a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "892a364e",
   "metadata": {},
   "source": [
    "12. Create a new column called \"Flagged\" -- this column will let the administration know that they need to contact the patient for more information. If the EmergencyContact column or the Allergies column have the following value \"Unknown - Ask Patient\" the \"Flagged\" column should have a value of 1, otherwise, it should have a value of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25e71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13aa6d32",
   "metadata": {},
   "source": [
    "13. Create a new column called \"Overdue Payment\" - if the \"outstanding balance\" column is greater than 0 and the \"new patient\" column is equal to \"N\" - the \"Overdue Payment\" column should have a value of 1, otherwise, it should have a value of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b95b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97529c03",
   "metadata": {},
   "source": [
    "14. Remove the \"Insurance\" column from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cbd83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f4a19bd",
   "metadata": {},
   "source": [
    "15. Export your modified dataset to an excel file called \"Dental Patients Updated\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75212c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
